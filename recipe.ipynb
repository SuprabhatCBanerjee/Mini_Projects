{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e039bd87",
   "metadata": {},
   "source": [
    "Scaled Dot-Product Attention\n",
    "\n",
    "Multi-Head Attention\n",
    "\n",
    "Feed-Forward Network\n",
    "\n",
    "Positional Encoding\n",
    "\n",
    "Decoder Block\n",
    "\n",
    "Full Transformer Decoder\n",
    "\n",
    "Training Loop (next-token prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e3ae9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "242fd5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaaee9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaled Dot-Product Attention\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super().__init__()\n",
    "        self.scale = math.sqrt(d_k)\n",
    "\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask==0, -1e9)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_weights, V)\n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9594be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-Head Attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.fc_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(self.d_k)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        B, T, D = x.size()\n",
    "        Q = self.W_q(x)\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "\n",
    "        #reshape\n",
    "        Q = Q.view(B, self.num_heads, T, self.d_k)\n",
    "        K = K.view(B, self.num_heads, T, self.d_k)\n",
    "        V = V.view(B, self.num_heads, T, self.d_k)\n",
    "\n",
    "        out, attn = self.attention(Q, K, V, mask)\n",
    "\n",
    "        #concat heads\n",
    "        out = out.transpose(1,2).contiguous().view(B, T, D) \n",
    "        out = self.fc_out(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b7a6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Position-wise Feed-Forward Network\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94e8592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Postional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.pe[:, :seq_len, :].to(x.device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48d23c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer Decoder block\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = PositionwiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        # self.dropout1 = nn.Dropout(0.1)\n",
    "        # self.dropout2 = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        #self-atttention with resuidual connection\n",
    "        attn_out = self.self_attn(x, mask)\n",
    "        x = x + self.norm1(x + attn_out)\n",
    "\n",
    "        #feed-forward with residual connection\n",
    "        ff_out = self.ff(x)\n",
    "        x = x + self.norm2(x + ff_out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d53cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Transformer Decoder\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=256, num_layers=4, num_heads=8, d_ff=512, max_len=512):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderBlock(d_model, num_heads, d_ff) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = torch.tril(torch.ones(sz, sz)).unsqueeze(0).unsqueeze(0) # o/p ===> (1, 1, sz, sz)\n",
    "        return mask \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mask = self.generate_square_subsequent_mask(x.size(1)).to(x.device)\n",
    "        x = self.token_embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        logits = self.fc_out(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72ea82c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op:  torch.Size([8, 50, 10000])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "if __name__ == \"__main__\":\n",
    "    vocab_size = 10000\n",
    "    seq_len = 50\n",
    "    batch_size = 8\n",
    "\n",
    "    model = TransformerDecoder(vocab_size = vocab_size)\n",
    "    x = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "    logits = model(x)\n",
    "    print(\"op: \",logits.shape)  # Expected output: (batch_size, seq_len, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a24b94a",
   "metadata": {},
   "source": [
    "Data Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b2aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset is taken from kaggle :-> https://www.kaggle.com/datasets/prashantsingh001/recipes-dataset-64k-dishes\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68203618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_recipe(recipe):\n",
    "    return f\"Title: {recipe['recipe_title']}\\nCategory: {recipe['category']}\\nDescription: {recipe['description']}\\nIngredients: {recipe['ingredients']}\\nDirections: {recipe['directions']}\"\n",
    "\n",
    "all_recipes = []\n",
    "\n",
    "df = pd.read_csv(\"1_Recipe_csv.csv\")\n",
    "\n",
    "df['recipe'] = df.apply(format_recipe, axis=1)\n",
    "\n",
    "data = df['recipe'].tolist()\n",
    "\n",
    "data = data[0:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1be37917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Spinach Ricotta Quiche\n",
      "Category: Allrecipes Allstar Recipes\n",
      "Description: This savory spinach and ricotta quiche is perfect for breakfast, brunch, or lunch. You can also serve it with a salad for a light dinner. It's light and fluffy with a creamy texture and bursting with delicious flavors!\n",
      "Ingredients: [\"1 (9 inch) pastry for single-crust pie\", \"1 tablespoon butter\", \"\\u2153 cup finely chopped red onion\", \"1 (8 ounce) package fresh spinach\", \"\\u00be cup whole-milk ricotta cheese\", \"\\u00be cup heavy cream\", \"\\u2153 cup grated Parmigiano-Reggiano cheese\", \"4 large eggs\", \"1 tablespoon chopped fresh basil\", \"\\u00bd teaspoon salt\", \"\\u00bc teaspoon ground black pepper\"]\n",
      "Directions: [\"Preheat the oven to 375 degrees F (190 degrees C). Press pie pastry into a 9-inch deep-dish pie pan; prick all over the bottom with a fork.\", \"Bake crust in the preheated oven for 10 minutes. Remove from the oven and let cool until needed.\", \"While the crust is cooling, melt butter in a skillet over medium heat; add onion and cook for 1 minute. Stir in spinach and cook until starting to wilt, about 1 minute. Cover and cook until condensation builds inside the skillet, about 1 minute. Remove the lid, stir to combine, and turn off the heat.\", \"Blend ricotta, cream, Parmigiano-Reggiano, eggs, basil, salt, and pepper in a blender or food processor until smooth.\", \"Spread spinach mixture evenly over crust, then pour in ricotta and egg mixture.\", \"Bake in the preheated oven until the center is set and the top is lightly browned, about 40 minutes. Let stand for 10 minutes before serving.\"]\n"
     ]
    }
   ],
   "source": [
    "print(data[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c9cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing and tokenization\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "def build_vocab(texts, vocab_size=10000):\n",
    "    words = Counter()\n",
    "    for text in texts:\n",
    "        words.update(re.findall(r'\\w+', text.lower()))\n",
    "    vocab = {word: i+2 for i, (word, _) in enumerate(words.most_common(vocab_size-2))}\n",
    "    vocab[\"<PAD>\"] = 0\n",
    "    vocab[\"<UNK>\"] = 1\n",
    "    vocab[\"<BOS>\"] = 2\n",
    "    vocab[\"<EOS>\"] = 3\n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocab(data)\n",
    "\n",
    "\n",
    "def tokenize(text, vocab):\n",
    "    return [vocab[\"<BOS>\"]]+[vocab.get(word, vocab[\"<UNK>\"]) for word in re.findall(r'\\w+', text.lower())]+[vocab[\"<EOS>\"]]\n",
    "\n",
    "tokenized_data = [tokenize(text, vocab) for text in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9638c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input-output\n",
    "inputs = [tokens[:-1] for tokens in tokenized_data]\n",
    "targets = [tokens[1:] for tokens in tokenized_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00fe0c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "inputs = pad_sequence([torch.tensor(seq) for seq in inputs], batch_first=True, padding_value=vocab[\"<PAD>\"])\n",
    "targets = pad_sequence([torch.tensor(seq) for seq in targets], batch_first=True, padding_value=vocab[\"<PAD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5168c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\supra\\AppData\\Local\\Temp\\ipykernel_23808\\3033977884.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x = [torch.tensor(x, dtype=torch.long) for x in inputs]\n",
      "C:\\Users\\supra\\AppData\\Local\\Temp\\ipykernel_23808\\3033977884.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y = [torch.tensor(y, dtype=torch.long) for y in targets]\n"
     ]
    }
   ],
   "source": [
    "# Data setting for training\n",
    "# Now, 'inputs' and 'targets' are ready for training the Transformer model.\n",
    "\n",
    "model = TransformerDecoder(vocab_size=len(vocab), d_model=128, num_layers=2, num_heads=4, d_ff=256, max_len=2000)\n",
    "model.to(device)\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_x = [torch.tensor(x, dtype=torch.long) for x in inputs]\n",
    "train_y = [torch.tensor(y, dtype=torch.long) for y in targets]\n",
    "\n",
    "dataset = TensorDataset(torch.nn.utils.rnn.pad_sequence(train_x, batch_first=True, padding_value=vocab[\"<PAD>\"]),\n",
    "                        torch.nn.utils.rnn.pad_sequence(train_y, batch_first=True, padding_value=vocab[\"<PAD>\"]))\n",
    "loader = DataLoader(dataset, batch_size=10, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a944744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.0036\n",
      "Epoch 2/5, Loss: 0.0036\n",
      "Epoch 3/5, Loss: 0.0036\n",
      "Epoch 4/5, Loss: 0.0031\n",
      "Epoch 5/5, Loss: 0.0034\n"
     ]
    }
   ],
   "source": [
    "#training loop and other components would go here\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab[\"<PAD>\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    # Training code would go here\n",
    "    for batch_inputs, batch_targets in loader:\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_targets = batch_targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "\n",
    "        loss = criterion(outputs.view(-1, len(vocab)), batch_targets.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(loader):.4f}\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08e5ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"transformer_recipe_model.pth\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b4bb677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bread best sourdough Category: appetizers then are great for a classic rye of honey is\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, vocab, idx_to_word, prompt, max_len=2000, temperature=0.8, top_k=40):\n",
    "    model.eval()\n",
    "    tokens = tokenize(prompt, vocab)\n",
    "    input_ids = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids)\n",
    "            next_token_logits = output[0, -1, :] / temperature\n",
    "\n",
    "            # repetition penalty\n",
    "            for token in set(input_ids[0][-5:].tolist()):\n",
    "                next_token_logits[token] -= 2.0\n",
    "\n",
    "            # top-k sampling\n",
    "            top_k_probs, top_k_indices = torch.topk(next_token_logits, top_k)\n",
    "            probs = torch.softmax(top_k_probs, dim=-1)\n",
    "            next_token = top_k_indices[torch.multinomial(probs, 1)].item()\n",
    "\n",
    "            # stop if EOS\n",
    "            if \"<EOS>\" in vocab and next_token == vocab[\"<EOS>\"]:\n",
    "                break\n",
    "\n",
    "            input_ids = torch.cat([input_ids, torch.tensor([[next_token]]).to(device)], dim=1)\n",
    "\n",
    "    return \" \".join(idx_to_word[i] for i in input_ids[0].tolist())\n",
    "\n",
    "\n",
    "\n",
    "idx_to_word = {idx: word for word, idx in vocab.items()}\n",
    "\n",
    "def clean_output(text):\n",
    "    text = text.replace(\"<BOS>\", \"\").replace(\"<EOS>\", \"\").strip()\n",
    "    text = text.replace(\"category\", \"\\n\\nCategory:\")\n",
    "    text = text.replace(\"description\", \"\\n\\nDescription:\")\n",
    "    text = text.replace(\"ingredients\", \"\\nIngredients:\")\n",
    "    text = text.replace(\"instructions\", \"\\nInstructions:\")\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.replace(\"u00bd\", \"½\").replace(\"u00bc\", \"¼\").replace(\"u00be\", \"¾\")\n",
    "    return text\n",
    "\n",
    "raw = generate_text(model, vocab, idx_to_word, prompt=\"bread\", max_len=2000)\n",
    "\n",
    "import codecs\n",
    "\n",
    "def clean_unicode(text):\n",
    "    return codecs.decode(text, 'unicode_escape')\n",
    "\n",
    "raw = clean_output(raw)\n",
    "\n",
    "raw = clean_unicode(raw)\n",
    "\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f54a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
